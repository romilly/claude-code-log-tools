{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Claude Code Logs to PostgreSQL\n",
    "\n",
    "This notebook imports Claude Code conversation logs from JSONL files into a PostgreSQL database with full-text search support.\n",
    "\n",
    "## Schema Overview\n",
    "\n",
    "- **sessions** - One row per Claude Code session\n",
    "- **messages** - One row per log entry (user message, assistant response, system, etc.)\n",
    "- **content_blocks** - One row per content block within a message (text, tool_use, tool_result, thinking)\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "1. PostgreSQL 13+ running (can be on a remote host)\n",
    "2. Create a `.env` file in the project root (copy from `.env.example`)\n",
    "3. Install dependencies: `pip install -r requirements.txt`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:18:16.856277452Z",
     "start_time": "2026-01-11T17:18:16.393451062Z"
    }
   },
   "source": "import json\nimport os\nfrom pathlib import Path\nfrom uuid import UUID\n\nimport psycopg2\nfrom dotenv import load_dotenv\n\n# Load environment variables from .env file\nload_dotenv()\n\n# Database configuration from environment\nDB_CONFIG = {\n    'host': os.getenv('CLAUDE_LOGS_DB_HOST', 'localhost'),\n    'port': int(os.getenv('CLAUDE_LOGS_DB_PORT', '5432')),\n    'database': os.getenv('CLAUDE_LOGS_DB_NAME', 'claude_logs'),\n    'user': os.getenv('CLAUDE_LOGS_DB_USER', 'postgres'),\n    'password': os.getenv('CLAUDE_LOGS_DB_PASSWORD', ''),\n}\n\nCLAUDE_LOGS_DIR = Path.home() / '.claude' / 'projects'\n\nprint(f\"Database host: {DB_CONFIG['host']}:{DB_CONFIG['port']}\")\nprint(f\"Database name: {DB_CONFIG['database']}\")\nprint(f\"Claude logs directory: {CLAUDE_LOGS_DIR}\")",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database host: s2ag:5432\n",
      "Database name: claude_logs\n",
      "Claude logs directory: /home/romilly/.claude/projects\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Database Connection"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:18:26.397127825Z",
     "start_time": "2026-01-11T17:18:26.002860021Z"
    }
   },
   "source": [
    "def test_connection():\n",
    "    \"\"\"Test database connection.\"\"\"\n",
    "    try:\n",
    "        conn = psycopg2.connect(**DB_CONFIG)\n",
    "        cur = conn.cursor()\n",
    "        cur.execute('SELECT version()')\n",
    "        version = cur.fetchone()[0]\n",
    "        cur.close()\n",
    "        conn.close()\n",
    "        print(f\"Connected successfully!\")\n",
    "        print(f\"PostgreSQL version: {version}\")\n",
    "        return True\n",
    "    except psycopg2.OperationalError as e:\n",
    "        print(f\"Connection failed: {e}\")\n",
    "        return False\n",
    "\n",
    "test_connection()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected successfully!\n",
      "PostgreSQL version: PostgreSQL 13.15 (Raspbian 13.15-0+deb11u1) on arm-unknown-linux-gnueabihf, compiled by gcc (Raspbian 10.2.1-6+rpi1) 10.2.1 20210110, 32-bit\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Schema\n",
    "\n",
    "Run this once to create the tables and indexes. Safe to re-run (uses IF NOT EXISTS)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:45:35.178404956Z",
     "start_time": "2025-12-22T11:45:34.994750106Z"
    }
   },
   "source": [
    "SCHEMA_SQL = \"\"\"\n",
    "-- Sessions table: one row per Claude Code session\n",
    "CREATE TABLE IF NOT EXISTS sessions (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    session_uuid UUID UNIQUE NOT NULL,\n",
    "    project_path TEXT,\n",
    "    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,\n",
    "    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,\n",
    "    total_input_tokens INT DEFAULT 0,\n",
    "    total_output_tokens INT DEFAULT 0\n",
    ");\n",
    "\n",
    "-- Messages table: one row per log entry (envelope only, content in content_blocks)\n",
    "CREATE TABLE IF NOT EXISTS messages (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    session_id INT NOT NULL REFERENCES sessions(id) ON DELETE CASCADE,\n",
    "    uuid TEXT,\n",
    "    type TEXT NOT NULL,           -- 'user', 'assistant', 'system', 'summary', etc.\n",
    "    role TEXT,                     -- 'user', 'assistant' (from message.role)\n",
    "    timestamp TIMESTAMPTZ,\n",
    "    cwd TEXT,\n",
    "    input_tokens INT,\n",
    "    output_tokens INT,\n",
    "    version TEXT\n",
    ");\n",
    "\n",
    "-- Content blocks table: one row per content block within a message\n",
    "CREATE TABLE IF NOT EXISTS content_blocks (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    message_id INT NOT NULL REFERENCES messages(id) ON DELETE CASCADE,\n",
    "    block_index INT NOT NULL,      -- order within the message\n",
    "    block_type TEXT NOT NULL,      -- 'text', 'tool_use', 'tool_result', 'thinking'\n",
    "    \n",
    "    -- Text content (for text, thinking, tool_result blocks)\n",
    "    text_content TEXT,\n",
    "    \n",
    "    -- Tool use fields\n",
    "    tool_name TEXT,                -- for tool_use blocks\n",
    "    tool_input JSONB,              -- for tool_use blocks (the input parameters)\n",
    "    tool_use_id TEXT,              -- links tool_use to its tool_result\n",
    "    \n",
    "    -- Full-text search on text content\n",
    "    content_tsvector tsvector GENERATED ALWAYS AS (\n",
    "        to_tsvector('english', COALESCE(text_content, ''))\n",
    "    ) STORED\n",
    ");\n",
    "\n",
    "-- Indexes for messages\n",
    "CREATE INDEX IF NOT EXISTS idx_messages_session_id ON messages(session_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_messages_type ON messages(type);\n",
    "CREATE INDEX IF NOT EXISTS idx_messages_timestamp ON messages(timestamp DESC);\n",
    "CREATE INDEX IF NOT EXISTS idx_messages_session_timestamp ON messages(session_id, timestamp DESC);\n",
    "\n",
    "-- Indexes for content_blocks\n",
    "CREATE INDEX IF NOT EXISTS idx_content_blocks_message_id ON content_blocks(message_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_content_blocks_type ON content_blocks(block_type);\n",
    "CREATE INDEX IF NOT EXISTS idx_content_blocks_tool_use_id ON content_blocks(tool_use_id);\n",
    "CREATE INDEX IF NOT EXISTS idx_content_blocks_tool_name ON content_blocks(tool_name);\n",
    "CREATE INDEX IF NOT EXISTS idx_content_blocks_fts ON content_blocks USING GIN(content_tsvector);\n",
    "\"\"\"\n",
    "\n",
    "def create_schema():\n",
    "    \"\"\"Create database schema.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(SCHEMA_SQL)\n",
    "    conn.commit()\n",
    "    cur.close()\n",
    "    conn.close()\n",
    "    print(\"Schema created successfully!\")\n",
    "\n",
    "create_schema()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Schema created successfully!\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discover Log Files"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:45:45.285433882Z",
     "start_time": "2025-12-22T11:45:44.950251318Z"
    }
   },
   "source": [
    "def find_jsonl_files():\n",
    "    \"\"\"Discover all JSONL files in Claude Code log directory.\"\"\"\n",
    "    if not CLAUDE_LOGS_DIR.exists():\n",
    "        print(f\"Error: Claude logs directory not found at {CLAUDE_LOGS_DIR}\")\n",
    "        return []\n",
    "    \n",
    "    jsonl_files = list(CLAUDE_LOGS_DIR.glob('**/*.jsonl'))\n",
    "    print(f\"Found {len(jsonl_files)} JSONL files\")\n",
    "    return jsonl_files\n",
    "\n",
    "log_files = find_jsonl_files()\n",
    "\n",
    "# Show first few files\n",
    "for f in log_files[:10]:\n",
    "    print(f\"  {f.relative_to(CLAUDE_LOGS_DIR)}\")\n",
    "if len(log_files) > 10:\n",
    "    print(f\"  ... and {len(log_files) - 10} more\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 220 JSONL files\n",
      "  -home-romilly-git-active-video-transcriber/agent-81b3a20c.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-a286637.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-aeac6d77.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-867d63b3.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-aed946a.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/f7f84c65-45e6-4255-949a-645d3f32f3a8.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/e91a98a1-1fcb-4f9f-904c-afd06ec20677.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-e021f857.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-a4b03da.jsonl\n",
      "  -home-romilly-git-active-video-transcriber/agent-92ee2965.jsonl\n",
      "  ... and 210 more\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Functions"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:45:53.864282040Z",
     "start_time": "2025-12-22T11:45:53.840738223Z"
    }
   },
   "source": [
    "def get_or_create_session(cur, session_uuid, project_path):\n",
    "    \"\"\"\n",
    "    Get session ID, creating it if needed.\n",
    "    Returns session_id.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        session_uuid = UUID(session_uuid) if isinstance(session_uuid, str) else session_uuid\n",
    "    except (ValueError, AttributeError):\n",
    "        pass\n",
    "    \n",
    "    cur.execute(\n",
    "        \"\"\"\n",
    "        INSERT INTO sessions (session_uuid, project_path, created_at, updated_at)\n",
    "        VALUES (%s, %s, CURRENT_TIMESTAMP, CURRENT_TIMESTAMP)\n",
    "        ON CONFLICT (session_uuid) DO UPDATE SET updated_at = CURRENT_TIMESTAMP\n",
    "        RETURNING id\n",
    "        \"\"\",\n",
    "        (str(session_uuid), project_path)\n",
    "    )\n",
    "    return cur.fetchone()[0]\n",
    "\n",
    "\n",
    "def insert_content_blocks(cur, message_id, content):\n",
    "    \"\"\"\n",
    "    Insert content blocks for a message.\n",
    "    \n",
    "    Content can be:\n",
    "    - A string (user messages)\n",
    "    - A list of block dicts (assistant messages)\n",
    "    \n",
    "    Returns number of blocks inserted.\n",
    "    \"\"\"\n",
    "    if content is None:\n",
    "        return 0\n",
    "    \n",
    "    # Handle string content (user messages)\n",
    "    if isinstance(content, str):\n",
    "        if not content.strip():\n",
    "            return 0\n",
    "        cur.execute(\n",
    "            \"\"\"\n",
    "            INSERT INTO content_blocks (message_id, block_index, block_type, text_content)\n",
    "            VALUES (%s, %s, %s, %s)\n",
    "            \"\"\",\n",
    "            (message_id, 0, 'text', content)\n",
    "        )\n",
    "        return 1\n",
    "    \n",
    "    # Handle list of content blocks (assistant messages)\n",
    "    if not isinstance(content, list):\n",
    "        return 0\n",
    "    \n",
    "    block_count = 0\n",
    "    for idx, block in enumerate(content):\n",
    "        if not isinstance(block, dict):\n",
    "            continue\n",
    "        \n",
    "        block_type = block.get('type', 'unknown')\n",
    "        \n",
    "        if block_type == 'text':\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO content_blocks (message_id, block_index, block_type, text_content)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                (message_id, idx, 'text', block.get('text', ''))\n",
    "            )\n",
    "            block_count += 1\n",
    "            \n",
    "        elif block_type == 'thinking':\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO content_blocks (message_id, block_index, block_type, text_content)\n",
    "                VALUES (%s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                (message_id, idx, 'thinking', block.get('thinking', ''))\n",
    "            )\n",
    "            block_count += 1\n",
    "            \n",
    "        elif block_type == 'tool_use':\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO content_blocks (\n",
    "                    message_id, block_index, block_type, \n",
    "                    tool_name, tool_input, tool_use_id\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                (\n",
    "                    message_id, idx, 'tool_use',\n",
    "                    block.get('name'),\n",
    "                    json.dumps(block.get('input', {})),\n",
    "                    block.get('id')\n",
    "                )\n",
    "            )\n",
    "            block_count += 1\n",
    "            \n",
    "        elif block_type == 'tool_result':\n",
    "            # tool_result content can be string or list\n",
    "            result_content = block.get('content', '')\n",
    "            if isinstance(result_content, list):\n",
    "                # Extract text from content blocks within the result\n",
    "                result_content = '\\n'.join(\n",
    "                    item.get('text', '') for item in result_content \n",
    "                    if isinstance(item, dict) and item.get('type') == 'text'\n",
    "                )\n",
    "            \n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                INSERT INTO content_blocks (\n",
    "                    message_id, block_index, block_type, \n",
    "                    text_content, tool_use_id\n",
    "                )\n",
    "                VALUES (%s, %s, %s, %s, %s)\n",
    "                \"\"\",\n",
    "                (\n",
    "                    message_id, idx, 'tool_result',\n",
    "                    result_content,\n",
    "                    block.get('tool_use_id')\n",
    "                )\n",
    "            )\n",
    "            block_count += 1\n",
    "    \n",
    "    return block_count\n",
    "\n",
    "\n",
    "def import_jsonl_file(filepath, conn):\n",
    "    \"\"\"\n",
    "    Import a single JSONL file into the database.\n",
    "    Returns: (message_count, block_count, error_count)\n",
    "    \"\"\"\n",
    "    cur = conn.cursor()\n",
    "    message_count = 0\n",
    "    block_count = 0\n",
    "    error_count = 0\n",
    "    session_id = None\n",
    "    \n",
    "    try:\n",
    "        project_path = str(filepath.parent.relative_to(CLAUDE_LOGS_DIR))\n",
    "    except ValueError:\n",
    "        project_path = str(filepath.parent)\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r') as f:\n",
    "            for line_num, line in enumerate(f, 1):\n",
    "                try:\n",
    "                    data = json.loads(line)\n",
    "                    \n",
    "                    # Create or get session\n",
    "                    if data.get('sessionId') and session_id is None:\n",
    "                        session_id = get_or_create_session(\n",
    "                            cur, \n",
    "                            data['sessionId'],\n",
    "                            project_path\n",
    "                        )\n",
    "                    \n",
    "                    if not session_id:\n",
    "                        continue\n",
    "                    \n",
    "                    # Extract message metadata\n",
    "                    message = data.get('message', {})\n",
    "                    usage = message.get('usage', {}) if isinstance(message, dict) else {}\n",
    "                    \n",
    "                    # Insert message (envelope)\n",
    "                    cur.execute(\n",
    "                        \"\"\"\n",
    "                        INSERT INTO messages (\n",
    "                            session_id, uuid, type, role,\n",
    "                            timestamp, cwd, input_tokens, output_tokens, version\n",
    "                        ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)\n",
    "                        RETURNING id\n",
    "                        \"\"\",\n",
    "                        (\n",
    "                            session_id,\n",
    "                            data.get('uuid'),\n",
    "                            data.get('type'),\n",
    "                            message.get('role') if isinstance(message, dict) else None,\n",
    "                            data.get('timestamp'),\n",
    "                            data.get('cwd'),\n",
    "                            usage.get('input_tokens') if isinstance(usage, dict) else None,\n",
    "                            usage.get('output_tokens') if isinstance(usage, dict) else None,\n",
    "                            data.get('version')\n",
    "                        )\n",
    "                    )\n",
    "                    message_id = cur.fetchone()[0]\n",
    "                    message_count += 1\n",
    "                    \n",
    "                    # Insert content blocks\n",
    "                    content = message.get('content') if isinstance(message, dict) else None\n",
    "                    block_count += insert_content_blocks(cur, message_id, content)\n",
    "                    \n",
    "                    # Commit every 100 messages\n",
    "                    if message_count % 100 == 0:\n",
    "                        conn.commit()\n",
    "                \n",
    "                except (json.JSONDecodeError, ValueError) as e:\n",
    "                    error_count += 1\n",
    "                    if error_count <= 3:\n",
    "                        print(f\"  Error at line {line_num}: {e}\")\n",
    "                    continue\n",
    "        \n",
    "        # Final commit\n",
    "        conn.commit()\n",
    "        \n",
    "        # Update session token totals\n",
    "        if session_id:\n",
    "            cur.execute(\n",
    "                \"\"\"\n",
    "                UPDATE sessions \n",
    "                SET total_input_tokens = (\n",
    "                    SELECT COALESCE(SUM(input_tokens), 0) FROM messages \n",
    "                    WHERE session_id = %s\n",
    "                ),\n",
    "                total_output_tokens = (\n",
    "                    SELECT COALESCE(SUM(output_tokens), 0) FROM messages \n",
    "                    WHERE session_id = %s\n",
    "                )\n",
    "                WHERE id = %s\n",
    "                \"\"\",\n",
    "                (session_id, session_id, session_id)\n",
    "            )\n",
    "            conn.commit()\n",
    "        \n",
    "        return message_count, block_count, error_count\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"  Failed to import: {e}\")\n",
    "        conn.rollback()\n",
    "        return 0, 0, -1\n",
    "    \n",
    "    finally:\n",
    "        cur.close()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Import"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:47:56.100716782Z",
     "start_time": "2025-12-22T11:46:13.067448148Z"
    }
   },
   "source": [
    "def import_all_logs(files):\n",
    "    \"\"\"Import all discovered log files.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    \n",
    "    total_messages = 0\n",
    "    total_blocks = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for i, filepath in enumerate(files, 1):\n",
    "        print(f\"[{i}/{len(files)}] {filepath.name}\")\n",
    "        messages, blocks, errors = import_jsonl_file(filepath, conn)\n",
    "        total_messages += messages\n",
    "        total_blocks += blocks\n",
    "        if errors > 0:\n",
    "            total_errors += errors\n",
    "        print(f\"  -> {messages} messages, {blocks} blocks ({errors} errors)\")\n",
    "    \n",
    "    conn.close()\n",
    "    \n",
    "    print(f\"\\n=== Import Complete ===\")\n",
    "    print(f\"Total messages: {total_messages}\")\n",
    "    print(f\"Total content blocks: {total_blocks}\")\n",
    "    print(f\"Total errors: {total_errors}\")\n",
    "\n",
    "# Run the import\n",
    "import_all_logs(log_files)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/220] agent-81b3a20c.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[2/220] agent-a286637.jsonl\n",
      "  -> 65 messages, 65 blocks (0 errors)\n",
      "[3/220] agent-aeac6d77.jsonl\n",
      "  -> 55 messages, 55 blocks (0 errors)\n",
      "[4/220] agent-867d63b3.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[5/220] agent-aed946a.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[6/220] f7f84c65-45e6-4255-949a-645d3f32f3a8.jsonl\n",
      "  -> 484 messages, 445 blocks (0 errors)\n",
      "[7/220] e91a98a1-1fcb-4f9f-904c-afd06ec20677.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[8/220] agent-e021f857.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[9/220] agent-a4b03da.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[10/220] agent-92ee2965.jsonl\n",
      "  -> 22 messages, 22 blocks (0 errors)\n",
      "[11/220] agent-addf4fbd.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[12/220] 0a87d7dd-26e1-48f0-841c-235d19244d8c.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[13/220] agent-d9737fb9.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[14/220] agent-73ac568a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[15/220] agent-7a3ede58.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[16/220] agent-5e3f1686.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[17/220] agent-a737d8d.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[18/220] agent-e489bd6c.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[19/220] 1a270edb-7583-432d-a42f-03d7ba5e8416.jsonl\n",
      "  -> 476 messages, 428 blocks (0 errors)\n",
      "[20/220] 6cacb0e5-63cd-47a4-b228-5b2147773e6e.jsonl\n",
      "  -> 481 messages, 448 blocks (0 errors)\n",
      "[21/220] 1c9cff04-1b4d-4003-b6f8-257266a80eaa.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[22/220] agent-a98c88f.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[23/220] d0a5ebed-e195-499f-8ce8-f46a9a00f60f.jsonl\n",
      "  -> 22 messages, 19 blocks (0 errors)\n",
      "[24/220] agent-7062ec4b.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[25/220] 962ca649-c00a-4acb-b627-78980868d076.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[26/220] agent-a2c3f71.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[27/220] 803389fe-468e-4082-b19e-dfdd3f2a2cf6.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[28/220] a593c7df-2a1a-446e-ac66-e3713fc6f677.jsonl\n",
      "  -> 113 messages, 107 blocks (0 errors)\n",
      "[29/220] agent-a741491.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[30/220] a1bc2b2c-b4f3-4915-8212-bd70490f77c7.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[31/220] 6127ebb4-c3d7-4d78-9084-1bb7a4ba2af6.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[32/220] abd61767-d1d2-4ac0-8747-5839477c2a63.jsonl\n",
      "  -> 1182 messages, 1103 blocks (0 errors)\n",
      "[33/220] agent-70d1d5e1.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[34/220] agent-3b238075.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[35/220] agent-a175fce.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[36/220] agent-0aaf33c9.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[37/220] agent-ac67fbb.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[38/220] agent-6e508518.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[39/220] agent-e24b504d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[40/220] f291a630-983b-42ab-a29b-ca37d7228dbd.jsonl\n",
      "  -> 130 messages, 119 blocks (0 errors)\n",
      "[41/220] agent-15369b6c.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[42/220] agent-a458bbf.jsonl\n",
      "  -> 72 messages, 72 blocks (0 errors)\n",
      "[43/220] agent-afdb4d4.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[44/220] agent-aa0beee.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[45/220] agent-712786b5.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[46/220] agent-eb3bc9b3.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[47/220] 1a1bcfa3-524c-4e4b-b7bd-85a98272fcbf.jsonl\n",
      "  -> 311 messages, 268 blocks (0 errors)\n",
      "[48/220] f41114ad-ae96-444e-b6cd-7184547f4e69.jsonl\n",
      "  -> 36 messages, 31 blocks (0 errors)\n",
      "[49/220] f98fe0c5-0e1c-488e-b3c6-ef83c010fc68.jsonl\n",
      "  -> 1480 messages, 1350 blocks (0 errors)\n",
      "[50/220] agent-a15368f.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[51/220] agent-0a483bfd.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[52/220] agent-09eb4302.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[53/220] agent-a513891.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[54/220] agent-25fe3000.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[55/220] 5b8f4114-eb9e-41fb-be75-29cf1116912c.jsonl\n",
      "  -> 77 messages, 65 blocks (0 errors)\n",
      "[56/220] agent-c1349e2b.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[57/220] agent-25057e43.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[58/220] agent-88eb93f3.jsonl\n",
      "  -> 48 messages, 48 blocks (0 errors)\n",
      "[59/220] agent-9b62fb07.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[60/220] agent-a01aa52.jsonl\n",
      "  -> 34 messages, 34 blocks (0 errors)\n",
      "[61/220] 55fe4f6f-e384-4e58-a2ee-88991dfd8d7c.jsonl\n",
      "  -> 92 messages, 85 blocks (0 errors)\n",
      "[62/220] agent-adeacac.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[63/220] agent-a7ac4e6.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[64/220] 15f1b43c-3eb8-4ba8-a38f-cdd4af16b305.jsonl\n",
      "  -> 339 messages, 319 blocks (0 errors)\n",
      "[65/220] agent-df3e6593.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[66/220] df5fbf52-659c-4c44-9d2e-1c16a0ce9552.jsonl\n",
      "  -> 253 messages, 244 blocks (0 errors)\n",
      "[67/220] 0d13d08c-e04b-4d08-96a1-f7bd30d8c910.jsonl\n",
      "  -> 99 messages, 96 blocks (0 errors)\n",
      "[68/220] agent-ac270a2.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[69/220] agent-dc46932a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[70/220] agent-0da3232d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[71/220] agent-a32e460.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[72/220] agent-4d9fff8a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[73/220] 0e3bf026-733a-4410-94dc-ce6962c72ee7.jsonl\n",
      "  -> 113 messages, 109 blocks (0 errors)\n",
      "[74/220] agent-aef4498.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[75/220] a2be3284-3a78-4241-93e6-257e78a77a4c.jsonl\n",
      "  -> 140 messages, 131 blocks (0 errors)\n",
      "[76/220] agent-a8a9f57.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[77/220] agent-1f71a6b0.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[78/220] agent-6f591c60.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[79/220] eeac1ff0-5473-4842-92f6-c589ab1c0d66.jsonl\n",
      "  -> 17 messages, 17 blocks (0 errors)\n",
      "[80/220] agent-ae56af2.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[81/220] agent-a0bc59f.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[82/220] 2fb0c530-5b76-4d8d-81b1-40d3ca03e8eb.jsonl\n",
      "  -> 14 messages, 2 blocks (0 errors)\n",
      "[83/220] agent-ab07538.jsonl\n",
      "  -> 53 messages, 53 blocks (0 errors)\n",
      "[84/220] agent-af93129.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[85/220] 56ae3ec2-f320-4ec4-83d0-509431f00fdc.jsonl\n",
      "  -> 19 messages, 15 blocks (0 errors)\n",
      "[86/220] agent-a920f19.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[87/220] agent-aa28d64.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[88/220] agent-a94926a.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[89/220] agent-ad0dee4.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[90/220] bc184250-1ac4-4546-943f-673fdc477b65.jsonl\n",
      "  -> 577 messages, 531 blocks (0 errors)\n",
      "[91/220] 85a14d7a-3ff4-4908-a093-70d32afdd631.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[92/220] agent-a4eb952.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[93/220] agent-7b80b407.jsonl\n",
      "  -> 16 messages, 16 blocks (0 errors)\n",
      "[94/220] agent-e78f363d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[95/220] agent-5df03990.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[96/220] agent-2b6e6ee1.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[97/220] agent-4d5fe43d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[98/220] agent-deee3293.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[99/220] agent-714e7e69.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[100/220] a976fd77-1c2f-4fb2-a5a8-6233c2c38371.jsonl\n",
      "  -> 94 messages, 83 blocks (0 errors)\n",
      "[101/220] agent-8d500b2e.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[102/220] agent-8f9e29a6.jsonl\n",
      "  -> 51 messages, 51 blocks (0 errors)\n",
      "[103/220] 9e1f4b01-a24e-45b1-8fc9-7cc392e55902.jsonl\n",
      "  -> 578 messages, 527 blocks (0 errors)\n",
      "[104/220] agent-00c88921.jsonl\n",
      "  -> 37 messages, 37 blocks (0 errors)\n",
      "[105/220] agent-1d920bf6.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[106/220] fff283fa-65db-42b9-b0ac-0971a9c86fc5.jsonl\n",
      "  -> 54 messages, 52 blocks (0 errors)\n",
      "[107/220] 0565175c-71d9-4968-91bb-9bf46eb98fa6.jsonl\n",
      "  -> 125 messages, 118 blocks (0 errors)\n",
      "[108/220] agent-aad5db4.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[109/220] 07849216-80da-4642-bfa1-15b7854e211c.jsonl\n",
      "  -> 300 messages, 270 blocks (0 errors)\n",
      "[110/220] agent-a5e0545.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[111/220] agent-a97dda4.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[112/220] 93146d0f-f07d-4ae7-8bb7-6245ca9ada68.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[113/220] agent-a063e87.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[114/220] agent-83d7eb57.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[115/220] 540af6b3-d815-4935-9047-c79dee84fc3f.jsonl\n",
      "  -> 451 messages, 397 blocks (0 errors)\n",
      "[116/220] agent-fb89fe3e.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[117/220] 786f4cc8-2daf-4b25-9dc0-d04195091fa7.jsonl\n",
      "  -> 293 messages, 274 blocks (0 errors)\n",
      "[118/220] agent-3a52fda8.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[119/220] agent-5b5cf37d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[120/220] agent-654e1958.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[121/220] agent-f51c791a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[122/220] 5fabddd4-b726-4f1e-82e5-522b6c49cfe6.jsonl\n",
      "  -> 136 messages, 125 blocks (0 errors)\n",
      "[123/220] 9af3180b-ad46-4a85-99e2-81059d2b9df9.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[124/220] agent-7c23280c.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[125/220] agent-c0e8769d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[126/220] 3bc7f675-99b2-4d22-bece-8829b0373dae.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[127/220] 0793cba6-0548-49b4-aaa5-30db7c993a6a.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[128/220] 5015ee13-462c-4a1b-b271-364b7f30283c.jsonl\n",
      "  -> 210 messages, 185 blocks (0 errors)\n",
      "[129/220] agent-e2404f12.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[130/220] agent-4ba70d41.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[131/220] agent-a82d994.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[132/220] agent-6277259b.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[133/220] agent-a0f3c65.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[134/220] agent-44913f02.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[135/220] agent-a7dc072.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[136/220] agent-a9fa66d.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[137/220] 38eec20c-d709-49b5-99c1-f7b018cd46f4.jsonl\n",
      "  Error at line 333: A string literal cannot contain NUL (0x00) characters.\n",
      "  -> 446 messages, 410 blocks (1 errors)\n",
      "[138/220] e539aa42-89b9-4fcb-87be-2c68b991d9c1.jsonl\n",
      "  -> 417 messages, 365 blocks (0 errors)\n",
      "[139/220] agent-34734069.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[140/220] agent-050a44d2.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[141/220] agent-a5e0361a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[142/220] agent-e468e0ea.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[143/220] d6c44cce-8af0-4bc3-976d-aa22976d2319.jsonl\n",
      "  -> 197 messages, 188 blocks (0 errors)\n",
      "[144/220] agent-369d57cb.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[145/220] agent-20b597f4.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[146/220] agent-4dd09514.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[147/220] c58def27-1d85-4c5e-825b-b3533f2cef56.jsonl\n",
      "  -> 346 messages, 311 blocks (0 errors)\n",
      "[148/220] agent-1699e859.jsonl\n",
      "  -> 36 messages, 36 blocks (0 errors)\n",
      "[149/220] agent-0ccaca02.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[150/220] agent-980a0e65.jsonl\n",
      "  -> 58 messages, 58 blocks (0 errors)\n",
      "[151/220] agent-b710a39a.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[152/220] agent-fdd85348.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[153/220] 507f4e93-a0e7-4bcf-ae69-54c6965b87af.jsonl\n",
      "  -> 371 messages, 352 blocks (0 errors)\n",
      "[154/220] agent-28c1e0ec.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[155/220] agent-93d286c7.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[156/220] 803e0500-ff75-4260-9a48-72d9e485eac6.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[157/220] agent-d3ff0622.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[158/220] agent-d8ece141.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[159/220] agent-a2768b93.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[160/220] agent-72c4b2fa.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[161/220] af711b01-5bf8-45fb-9724-b560037396d4.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[162/220] agent-fc544ef4.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[163/220] agent-6e7fbb1d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[164/220] agent-b58b8ae9.jsonl\n",
      "  -> 12 messages, 12 blocks (0 errors)\n",
      "[165/220] agent-ab6a4fa8.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[166/220] agent-85182de0.jsonl\n",
      "  -> 22 messages, 22 blocks (0 errors)\n",
      "[167/220] c04d1bc4-bbba-4991-b801-4c9f7223598a.jsonl\n",
      "  -> 305 messages, 293 blocks (0 errors)\n",
      "[168/220] d6b043da-6697-4308-a1ae-24597c95cf82.jsonl\n",
      "  -> 381 messages, 362 blocks (0 errors)\n",
      "[169/220] agent-8b620406.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[170/220] agent-4c98ddcd.jsonl\n",
      "  -> 36 messages, 36 blocks (0 errors)\n",
      "[171/220] 47125c31-8bb3-4b08-96dc-163dfcec8c51.jsonl\n",
      "  -> 619 messages, 593 blocks (0 errors)\n",
      "[172/220] 874222c5-2ce6-4d0d-8a19-768c02cf2aa4.jsonl\n",
      "  -> 96 messages, 89 blocks (0 errors)\n",
      "[173/220] 3a3655e8-bde9-4287-9422-8e39a775a5d8.jsonl\n",
      "  -> 57 messages, 56 blocks (0 errors)\n",
      "[174/220] agent-a94fc779.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[175/220] agent-533b66f5.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[176/220] agent-f0a244b7.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[177/220] agent-27343713.jsonl\n",
      "  -> 72 messages, 72 blocks (0 errors)\n",
      "[178/220] agent-58334cf6.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[179/220] d5254f5f-b8c0-4297-ba55-9367c217e1cf.jsonl\n",
      "  -> 24 messages, 21 blocks (0 errors)\n",
      "[180/220] agent-de0a1645.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[181/220] agent-57fbaa7d.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[182/220] agent-679603de.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[183/220] agent-95a527df.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[184/220] agent-8f9352dc.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[185/220] agent-31f10e1f.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[186/220] agent-72752b71.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[187/220] agent-5512b6af.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[188/220] 47c98af8-3e69-4c08-9b14-aa06fd69306c.jsonl\n",
      "  -> 5 messages, 0 blocks (0 errors)\n",
      "[189/220] agent-5c60ea24.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[190/220] 4f839fa5-fd3b-486f-b421-71bfbd4f1e4d.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[191/220] agent-87b42270.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[192/220] agent-29a33ccb.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[193/220] agent-539a4c20.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[194/220] 13e1f815-2f9c-4edf-92cd-7c0884b73997.jsonl\n",
      "  -> 429 messages, 407 blocks (0 errors)\n",
      "[195/220] agent-59a95398.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[196/220] def78335-65d1-4d65-8480-54ca33f155a3.jsonl\n",
      "  -> 603 messages, 546 blocks (0 errors)\n",
      "[197/220] 91a80142-ede1-4eae-994a-0bf94d6d893f.jsonl\n",
      "  -> 289 messages, 257 blocks (0 errors)\n",
      "[198/220] 528904ae-1241-4fef-82df-f24ad67fc170.jsonl\n",
      "  -> 180 messages, 160 blocks (0 errors)\n",
      "[199/220] 2cc1d54e-af86-4aca-913e-91461851fcb3.jsonl\n",
      "  -> 53 messages, 40 blocks (0 errors)\n",
      "[200/220] agent-5eee29c1.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[201/220] agent-a0d2803.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[202/220] agent-a504bda.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[203/220] 231204ae-9700-44b1-b756-7d5673c8861f.jsonl\n",
      "  -> 119 messages, 109 blocks (0 errors)\n",
      "[204/220] agent-3a643ffc.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[205/220] b1aa5e43-aadb-4fde-9c8a-d167ece971a8.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[206/220] agent-a45144a7.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[207/220] agent-a3d7f73b.jsonl\n",
      "  -> 1 messages, 1 blocks (0 errors)\n",
      "[208/220] 21c06a6e-17b1-4b66-837e-983fd0a0d70b.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[209/220] agent-a35f204.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[210/220] agent-ab70ee5.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[211/220] agent-a8bfd94.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[212/220] agent-aae3abf.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[213/220] fa782cfb-c147-42f7-b035-6fd76fde1146.jsonl\n",
      "  -> 0 messages, 0 blocks (0 errors)\n",
      "[214/220] agent-a03e83a.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[215/220] agent-aea2bb6.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[216/220] bf85dd79-4426-4e9c-932f-0d2c33b77ab4.jsonl\n",
      "  -> 423 messages, 392 blocks (0 errors)\n",
      "[217/220] 1476b3d7-a4b1-4a74-8f55-620cb75a01a8.jsonl\n",
      "  -> 22 messages, 11 blocks (0 errors)\n",
      "[218/220] agent-a7121f1.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[219/220] agent-a6b8444.jsonl\n",
      "  -> 2 messages, 2 blocks (0 errors)\n",
      "[220/220] dd99ebdd-5479-4fbe-ad07-327c4f25babc.jsonl\n",
      "  -> 512 messages, 478 blocks (0 errors)\n",
      "\n",
      "=== Import Complete ===\n",
      "Total messages: 15466\n",
      "Total content blocks: 14279\n",
      "Total errors: 1\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Import"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:18:59.156754708Z",
     "start_time": "2026-01-11T17:18:58.999017852Z"
    }
   },
   "source": [
    "def show_stats():\n",
    "    \"\"\"Show database statistics.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"SELECT COUNT(*) FROM sessions\")\n",
    "    session_count = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute(\"SELECT COUNT(*) FROM messages\")\n",
    "    message_count = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute(\"SELECT COUNT(*) FROM content_blocks\")\n",
    "    block_count = cur.fetchone()[0]\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT block_type, COUNT(*) \n",
    "        FROM content_blocks \n",
    "        GROUP BY block_type \n",
    "        ORDER BY COUNT(*) DESC\n",
    "    \"\"\")\n",
    "    block_types = cur.fetchall()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            COALESCE(SUM(input_tokens), 0) as total_input,\n",
    "            COALESCE(SUM(output_tokens), 0) as total_output\n",
    "        FROM messages\n",
    "    \"\"\")\n",
    "    tokens = cur.fetchone()\n",
    "    \n",
    "    print(f\"Sessions: {session_count}\")\n",
    "    print(f\"Messages: {message_count}\")\n",
    "    print(f\"Content blocks: {block_count}\")\n",
    "    print(f\"\\nBlock types:\")\n",
    "    for block_type, count in block_types:\n",
    "        print(f\"  {block_type}: {count}\")\n",
    "    print(f\"\\nTotal tokens: {tokens[0] + tokens[1]:,}\")\n",
    "    print(f\"  Input: {tokens[0]:,}\")\n",
    "    print(f\"  Output: {tokens[1]:,}\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "show_stats()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sessions: 67\n",
      "Messages: 15466\n",
      "Content blocks: 14279\n",
      "\n",
      "Block types:\n",
      "  tool_use: 3762\n",
      "  tool_result: 3761\n",
      "  thinking: 3385\n",
      "  text: 3371\n",
      "\n",
      "Total tokens: 1,778,965\n",
      "  Input: 532,834\n",
      "  Output: 1,246,131\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Test: Full-Text Search"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-01-11T17:22:11.803476411Z",
     "start_time": "2026-01-11T17:22:11.593921876Z"
    }
   },
   "source": [
    "def search(query_text, limit=5):\n",
    "    \"\"\"Search text content across all block types.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            cb.id,\n",
    "            cb.block_type,\n",
    "            m.timestamp,\n",
    "            m.type as message_type,\n",
    "            LEFT(cb.text_content, 200) as content_preview,\n",
    "            ts_rank(cb.content_tsvector, q.query) AS relevance\n",
    "        FROM content_blocks cb\n",
    "        JOIN messages m ON cb.message_id = m.id,\n",
    "             plainto_tsquery('english', %s) q(query)\n",
    "        WHERE cb.content_tsvector @@ q.query\n",
    "        ORDER BY relevance DESC, m.timestamp DESC\n",
    "        LIMIT %s\n",
    "    \"\"\", (query_text, limit))\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "    \n",
    "    print(f\"Search: '{query_text}' ({len(results)} results)\\n\")\n",
    "    for block_id, block_type, timestamp, msg_type, preview, relevance in results:\n",
    "        print(f\"[{relevance:.3f}] {timestamp} ({msg_type}/{block_type})\")\n",
    "        print(f\"  {preview}...\")\n",
    "        print()\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "# Try a search\n",
    "search('Hexagonal', 20)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search: 'Hexagonal' (20 results)\n",
      "\n",
      "[0.098] 2025-12-17 15:56:54.592000+00:00 (user/tool_result)\n",
      "  Web search results for query: \"Hexagonal Architecture Ports and Adapters Alistair Cockburn history origins 2005\"\n",
      "\n",
      "Links: [{\"title\":\"Hexagonal architecture (software) - Wikipedia\",\"url\":\"https://en.wik...\n",
      "\n",
      "[0.097] 2025-12-08 09:59:38.032000+00:00 (user/tool_result)\n",
      "  Excellent! Now I have all the information I need. Let me compile a comprehensive recommendations report:\n",
      "\n",
      "## Hexagonal Architecture Implementation Recommendations for Transcriber Application\n",
      "\n",
      "Based on...\n",
      "\n",
      "[0.097] 2025-12-08 09:59:37.917000+00:00 (assistant/text)\n",
      "  Excellent! Now I have all the information I need. Let me compile a comprehensive recommendations report:\n",
      "\n",
      "## Hexagonal Architecture Implementation Recommendations for Transcriber Application\n",
      "\n",
      "Based on...\n",
      "\n",
      "[0.097] 2025-12-08 09:57:17.199000+00:00 (user/tool_result)\n",
      "  Web search results for query: \"hexagonal architecture Python best practices 2025\"\n",
      "\n",
      "Links: [{\"title\":\"Structure a Python project in hexagonal architecture using AWS Lambda - AWS Prescriptive Guidance\",...\n",
      "\n",
      "[0.096] 2025-12-08 09:57:18.796000+00:00 (user/tool_result)\n",
      "  Web search results for query: \"refactoring to hexagonal architecture incrementally Python TDD\"\n",
      "\n",
      "Links: [{\"title\":\"Refactoring to Hexagonal Architecture Course by Ted M. Young\",\"url\":\"https://ted.dev/r...\n",
      "\n",
      "[0.096] 2025-12-08 09:57:40.688000+00:00 (user/tool_result)\n",
      "  Web search results for query: \"hexagonal architecture Python directory structure domain application infrastructure\"\n",
      "\n",
      "Links: [{\"title\":\"Structure a Python project in hexagonal architecture using AWS La...\n",
      "\n",
      "[0.094] 2025-12-08 14:13:00.480000+00:00 (user/tool_result)\n",
      "       1→# Hexagonal Architecture Refactoring Plan with TDD\n",
      "     2→\n",
      "     3→## Overview\n",
      "     4→\n",
      "     5→Refactor the transcriber application to hexagonal architecture (ports & adapters) to improve testabi...\n",
      "\n",
      "[0.094] 2025-12-08 10:47:23.606000+00:00 (user/tool_result)\n",
      "       1→# Hexagonal Architecture Refactoring Plan with TDD\n",
      "     2→\n",
      "     3→## Overview\n",
      "     4→\n",
      "     5→Refactor the transcriber application to hexagonal architecture (ports & adapters) to improve testabi...\n",
      "\n",
      "[0.094] 2025-12-08 10:26:04.887000+00:00 (user/tool_result)\n",
      "  User has approved your plan. You can now start coding. Start with updating your todo list if applicable\n",
      "\n",
      "Your plan has been saved to: /home/romilly/.claude/plans/stateless-launching-storm.md\n",
      "You can r...\n",
      "\n",
      "[0.094] 2025-11-23 10:01:39.630000+00:00 (user/tool_result)\n",
      "  The file /home/romilly/git/active/project-database/CLAUDE.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n",
      "     1→# CLAUDE.md\n",
      "     2→\n",
      "     3→This file provid...\n",
      "\n",
      "[0.094] 2025-11-23 09:57:01.816000+00:00 (user/tool_result)\n",
      "       1→# CLAUDE.md\n",
      "     2→\n",
      "     3→This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.\n",
      "     4→\n",
      "     5→## Project Overview\n",
      "     6→\n",
      "     7→**project-dat...\n",
      "\n",
      "[0.093] 2025-12-01 16:44:36.309000+00:00 (user/text)\n",
      "  This session is being continued from a previous conversation that ran out of context. The conversation is summarized below:\n",
      "Analysis:\n",
      "Let me chronologically analyze this conversation, which is a conti...\n",
      "\n",
      "[0.093] 2025-11-29 13:55:46.388000+00:00 (user/tool_result)\n",
      "       1→# Project Database - Progress Report\n",
      "     2→**Date:** November 19, 2025\n",
      "     3→\n",
      "     4→## Summary\n",
      "     5→Built a production-ready README generation system using hexagonal architecture (ports an...\n",
      "\n",
      "[0.093] 2025-11-23 09:56:51.003000+00:00 (user/tool_result)\n",
      "       1→# Project Database - Progress Report\n",
      "     2→**Date:** November 19, 2025\n",
      "     3→\n",
      "     4→## Summary\n",
      "     5→Built a production-ready README generation system using hexagonal architecture (ports an...\n",
      "\n",
      "[0.092] 2025-12-08 09:58:32.295000+00:00 (user/tool_result)\n",
      "  Based on my thorough exploration of the testing infrastructure in the transcriber project, here are my findings:\n",
      "\n",
      "## Testing Infrastructure Assessment\n",
      "\n",
      "### What Exists Currently\n",
      "\n",
      "**1. Test Directory S...\n",
      "\n",
      "[0.092] 2025-12-08 09:58:32.234000+00:00 (assistant/text)\n",
      "  Based on my thorough exploration of the testing infrastructure in the transcriber project, here are my findings:\n",
      "\n",
      "## Testing Infrastructure Assessment\n",
      "\n",
      "### What Exists Currently\n",
      "\n",
      "**1. Test Directory S...\n",
      "\n",
      "[0.092] 2025-12-08 09:57:18.214000+00:00 (user/tool_result)\n",
      "  Web search results for query: \"Python ports and adapters pattern implementation ABC Protocol\"\n",
      "\n",
      "Links: [{\"title\":\"Python Nameko ports and adapters (hexagonal) architecture example\",\"url\":\"https://jorze...\n",
      "\n",
      "[0.091] 2025-12-02 15:12:47.464000+00:00 (user/text)\n",
      "  This session is being continued from a previous conversation that ran out of context. The conversation is summarized below:\n",
      "Analysis:\n",
      "Let me chronologically analyze this conversation, which is a conti...\n",
      "\n",
      "[0.089] 2025-12-08 10:07:24.809000+00:00 (user/tool_result)\n",
      "  I understand - I'm in read-only mode and cannot write files. Let me provide you with a comprehensive implementation plan directly in my response.\n",
      "\n",
      "---\n",
      "\n",
      "# Hexagonal Architecture Refactoring Plan with T...\n",
      "\n",
      "[0.089] 2025-12-08 10:07:24.706000+00:00 (assistant/text)\n",
      "  I understand - I'm in read-only mode and cannot write files. Let me provide you with a comprehensive implementation plan directly in my response.\n",
      "\n",
      "---\n",
      "\n",
      "# Hexagonal Architecture Refactoring Plan with T...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Failed Tool Calls\n",
    "\n",
    "Example query to find tool calls that resulted in errors."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-12-22T11:49:23.961754780Z",
     "start_time": "2025-12-22T11:49:23.839689180Z"
    }
   },
   "source": [
    "def find_failed_tool_calls(limit=10):\n",
    "    \"\"\"Find tool calls where the result contains error indicators.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT \n",
    "            m.timestamp,\n",
    "            s.project_path,\n",
    "            cb_call.tool_name,\n",
    "            LEFT(cb_result.text_content, 300) as result_preview\n",
    "        FROM content_blocks cb_result\n",
    "        JOIN content_blocks cb_call \n",
    "            ON cb_call.tool_use_id = cb_result.tool_use_id \n",
    "            AND cb_call.block_type = 'tool_use'\n",
    "        JOIN messages m ON cb_result.message_id = m.id\n",
    "        JOIN sessions s ON m.session_id = s.id\n",
    "        WHERE cb_result.block_type = 'tool_result'\n",
    "          AND cb_result.content_tsvector @@ to_tsquery('english', \n",
    "              'error | failed | exception | traceback | denied'\n",
    "          )\n",
    "        ORDER BY m.timestamp DESC\n",
    "        LIMIT %s\n",
    "    \"\"\", (limit,))\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "    \n",
    "    print(f\"Found {len(results)} failed tool calls:\\n\")\n",
    "    for timestamp, project, tool_name, preview in results:\n",
    "        print(f\"{timestamp} [{project}]\")\n",
    "        print(f\"  Tool: {tool_name}\")\n",
    "        print(f\"  Result: {preview}...\")\n",
    "        print()\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "find_failed_tool_calls()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 failed tool calls:\n",
      "\n",
      "2025-12-22 11:34:12.594000+00:00 [-home-romilly-git-active-claude-code-log-tools]\n",
      "  Tool: Write\n",
      "  Result: The file /home/romilly/git/active/claude-code-log-tools/notebooks/01_import_logs.ipynb has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n",
      "     1→{\n",
      "     2→ \"cells\": [\n",
      "     3→  {\n",
      "     4→   \"cell_type\": \"markdown\",\n",
      "     5→   \"metadata\": {},\n",
      "     6→   \"source\": [\n",
      "  ...\n",
      "\n",
      "2025-12-22 11:32:32.674000+00:00 [-home-romilly-git-active-claude-code-log-tools]\n",
      "  Tool: Read\n",
      "  Result: <cell id=\"cell-0\"><cell_type>markdown</cell_type># Import Claude Code Logs to PostgreSQL\n",
      "\n",
      "This notebook imports Claude Code conversation logs from JSONL files into a PostgreSQL database with full-text search support.\n",
      "\n",
      "## Prerequisites\n",
      "\n",
      "1. PostgreSQL 13+ running (can be on a remote host)\n",
      "2. Create a ...\n",
      "\n",
      "2025-12-22 11:15:41.162000+00:00 [-home-romilly-git-active-claude-code-log-tools]\n",
      "  Tool: Read\n",
      "  Result:      1→# PostgreSQL Full-Text Search Setup for Claude Code Logs\n",
      "     2→\n",
      "     3→A practical guide to storing and searching Claude Code conversation logs using PostgreSQL with native full-text search (`tsvector`). This setup prioritizes speed and simplicity—no fuzzy matching, just fast exact-match ful...\n",
      "\n",
      "2025-12-21 15:06:39.369000+00:00 [-home-romilly-git-active-video-project-textual-gui]\n",
      "  Tool: Edit\n",
      "  Result: The file /home/romilly/git/active/video-project-textual-gui/CLAUDE.md has been updated. Here's the result of running `cat -n` on a snippet of the edited file:\n",
      "    18→When calling an API you haven't used before in this project:\n",
      "    19→1. Fetch the official documentation immediately before writing the...\n",
      "\n",
      "2025-12-21 11:33:10.005000+00:00 [-home-romilly-git-active-weekly-planning]\n",
      "  Tool: Bash\n",
      "  Result: dd8b3de Added dataflow diagram.\n",
      "f44ed5f Update progress report for 2025-12-18\n",
      "e775d5f Release v0.2.0 on PyPI\n",
      "6d90281 Update demo script and README to use test data\n",
      "dc9bd34 Fix gitignore path for tests/data/generated\n",
      "9933b6b Fix integration tests to use tracked test data\n",
      "9f94623 Preparing for package...\n",
      "\n",
      "2025-12-21 11:32:31.101000+00:00 [-home-romilly-git-active-weekly-planning]\n",
      "  Tool: Read\n",
      "  Result:      1→- Journal\n",
      "     2→- [[MoSCoW]]\n",
      "     3→\t- #must (**timebox**)\n",
      "     4→\t\t- DONE cancel Vocal Image\n",
      "     5→\t\t  :LOGBOOK:\n",
      "     6→\t\t  CLOCK: [2025-12-15 Mon 13:45:02]--[2025-12-15 Mon 13:45:02] =>  00:00:00\n",
      "     7→\t\t  :END:\n",
      "     8→\t\t- DONE Add Gui in [[project/video-transcriber-gui]]\n",
      "     9→\t\t  :LOG...\n",
      "\n",
      "2025-12-21 11:05:41.884000+00:00 [-home-romilly-git-active-video-transcriber]\n",
      "  Tool: Task\n",
      "  Result: Perfect! Now I have a comprehensive understanding of the codebase. Let me create a detailed summary report.\n",
      "\n",
      "## Video-Transcriber Complete Data Flow Analysis\n",
      "\n",
      "I've thoroughly explored the video-transcriber codebase. Here's a comprehensive breakdown of the complete architecture and data flow:\n",
      "\n",
      "### 1....\n",
      "\n",
      "2025-12-21 11:04:55.111000+00:00 [-home-romilly-git-active-video-transcriber]\n",
      "  Tool: Read\n",
      "  Result:      1→\"\"\"Integration tests for audio adapters.\n",
      "     2→\n",
      "     3→These tests require:\n",
      "     4→- ffmpeg installed on the system\n",
      "     5→- A test video file with audio\n",
      "     6→- faster-whisper installed\n",
      "     7→\"\"\"\n",
      "     8→\n",
      "     9→import pytest\n",
      "    10→import tempfile\n",
      "    11→from pathlib import Path\n",
      "    12→\n",
      " ...\n",
      "\n",
      "2025-12-21 11:04:55.110000+00:00 [-home-romilly-git-active-video-transcriber]\n",
      "  Tool: Read\n",
      "  Result:      1→\"\"\"Integration tests for OpenCVVideoAdapter.\n",
      "     2→\n",
      "     3→These tests require a test video file to be present.\n",
      "     4→\"\"\"\n",
      "     5→\n",
      "     6→import numpy as np\n",
      "     7→import pytest\n",
      "     8→from pathlib import Path\n",
      "     9→\n",
      "    10→from video_transcriber.adapters.opencv_video import OpenCVVideoAdap...\n",
      "\n",
      "2025-12-21 11:04:52.896000+00:00 [-home-romilly-git-active-video-transcriber]\n",
      "  Tool: Read\n",
      "  Result:      1→\"\"\"Fake implementations of audio ports for testing.\"\"\"\n",
      "     2→\n",
      "     3→from video_transcriber.ports.audio_extractor import AudioExtractionError\n",
      "     4→from video_transcriber.ports.audio_transcriber import AudioTranscriptionError\n",
      "     5→from video_transcriber.domain.models import AudioSegment\n",
      " ...\n",
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tool Usage Summary\n",
    "\n",
    "See which tools are used most frequently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool_usage_summary():\n",
    "    \"\"\"Show tool usage statistics.\"\"\"\n",
    "    conn = psycopg2.connect(**DB_CONFIG)\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"\n",
    "        SELECT tool_name, COUNT(*) as usage_count\n",
    "        FROM content_blocks\n",
    "        WHERE block_type = 'tool_use'\n",
    "          AND tool_name IS NOT NULL\n",
    "        GROUP BY tool_name\n",
    "        ORDER BY usage_count DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    results = cur.fetchall()\n",
    "    \n",
    "    print(\"Tool usage summary:\\n\")\n",
    "    for tool_name, count in results:\n",
    "        print(f\"  {tool_name}: {count}\")\n",
    "    \n",
    "    cur.close()\n",
    "    conn.close()\n",
    "\n",
    "tool_usage_summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
